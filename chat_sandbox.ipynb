{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from main import init_env_vars\n",
    "from langchain import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "init_env_vars()\n",
    "\n",
    "db = FAISS.load_local('index', OpenAIEmbeddings())\n",
    "retriever = db.as_retriever(search_type='similarity', search_kwargs={'k': 4})\n",
    "\n",
    "\n",
    "def ask_bot(question, ai_instruction):\n",
    "    system_template = ai_instruction + \"\\n\\n{summaries}\"\n",
    "    messages = [\n",
    "        SystemMessagePromptTemplate.from_template(system_template),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "    ]\n",
    "    chain_type_kwargs = {\"prompt\": ChatPromptTemplate.from_messages(messages)}\n",
    "    qa = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=ChatOpenAI(temperature=0),\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs=chain_type_kwargs)\n",
    "    result = qa({\"question\": question})\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T11:42:42.047335978Z",
     "start_time": "2023-06-06T11:42:41.149052484Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_sources(result):\n",
    "    source_urls = []\n",
    "    for document in result['source_documents']:\n",
    "        url = document.metadata['source'].replace(\"website/\", \"https://\")\n",
    "        if url not in source_urls:\n",
    "            source_urls.append(url)\n",
    "\n",
    "    return source_urls"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T11:42:44.188260931Z",
     "start_time": "2023-06-06T11:42:44.182018852Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can easily return source documents from the ConversationalRetrievalChain by setting the parameter `return_source_documents` to `True`. This is useful for when you want to inspect what documents were returned. Here's an example:\n",
      "\n",
      "```\n",
      "from langchain.chains import ConversationalRetrievalChain\n",
      "from langchain import vectorstore\n",
      "from langchain.vectorstore import as_retriever\n",
      "\n",
      "# create a vectorstore retriever\n",
      "retriever = vectorstore.as_retriever()\n",
      "\n",
      "# create the ConversationalRetrievalChain\n",
      "chain = ConversationalRetrievalChain(retriever, return_source_documents=True)\n",
      "\n",
      "# set up some chat history and a query\n",
      "chat_history = []\n",
      "query = \"What did the president say about Ketanji Brown Jackson\"\n",
      "\n",
      "# run the chain\n",
      "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
      "\n",
      "# get the source documents\n",
      "source_docs = result['source_documents']\n",
      "```\n",
      "\n",
      "In this example, `source_docs` will contain a list of the source documents that were returned by the retriever.\n",
      "['https://python.langchain.com/en/latest/integrations/vectara/vectara_chat.html', 'https://python.langchain.com/en/latest/modules/chains/index_examples/chat_vector_db.html', 'https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/weaviate.html']\n"
     ]
    }
   ],
   "source": [
    "# ai_instruction = \"Give your answer in a bullet point format to be used for slide presentations\"\n",
    "ai_instruction = \"\"\n",
    "question = \"Can ConversationalRetrievalChain also return the source documents?\"\n",
    "\n",
    "response = ask_bot(question, ai_instruction)\n",
    "\n",
    "print(response['answer'])\n",
    "print(get_sources(response))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-06T11:46:01.769430950Z",
     "start_time": "2023-06-06T11:45:40.937550207Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
